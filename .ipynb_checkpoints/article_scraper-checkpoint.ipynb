{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9f4ea9b",
   "metadata": {},
   "source": [
    "# Article Web Scraper\n",
    "\n",
    "## Introduction\n",
    "This notebook scrapes the latest articles from Ledger Insights and Blockworks websites and appends the data to a single CSV file named `scraped_articles.csv`. The notebook ensures that the CSV file is not overwritten but appended with new data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94590848",
   "metadata": {},
   "source": [
    "## Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866dbe9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import time\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576b2b77",
   "metadata": {},
   "source": [
    "## Setup and CSV Handling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5e1592",
   "metadata": {},
   "source": [
    "#### Load configuration from JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a6f115",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config.json', 'r') as config_file:\n",
    "    config = json.load(config_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548a30d5",
   "metadata": {},
   "source": [
    "#### Extract configuration parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32e87c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "webdriver_path = config['webdriver_path']\n",
    "ledger_insights_url = config['ledger_insights_url']\n",
    "blockworks_url = config['blockworks_url']\n",
    "keywords = config['keywords']\n",
    "num_clicks_li = config['num_clicks_li']\n",
    "num_clicks_bw = config['num_clicks_bw']\n",
    "searchword = config['searchword']\n",
    "csv_file_path = config['csv_file_path']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a773ead0",
   "metadata": {},
   "source": [
    "#### CSV checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e774e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check if the CSV file exists and contains headers\n",
    "def csv_file_exists_and_has_headers(file_path, headers):\n",
    "    if not os.path.isfile(file_path):\n",
    "        return False\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        first_line = file.readline().strip()\n",
    "        if first_line != ','.join(headers):\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "# Function to append data to CSV\n",
    "def append_to_csv(file_path, data, headers):\n",
    "    file_has_headers = csv_file_exists_and_has_headers(file_path, headers)\n",
    "    with open(file_path, mode='a', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        if not file_has_headers:\n",
    "            writer.writerow(headers)\n",
    "        writer.writerows(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8dfc8b1",
   "metadata": {},
   "source": [
    "#### Selenium setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb8b194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Selenium WebDriver\n",
    "service = Service(webdriver_path)\n",
    "options = Options()\n",
    "# options.add_argument('--headless')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afcc9a6c",
   "metadata": {},
   "source": [
    "#### Interacting with cookie consent button"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3738df25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to close cookie consent button\n",
    "def close_cookie_consent():\n",
    "    try:\n",
    "        cookie_button = WebDriverWait(driver, 10).until(\n",
    "            EC.element_to_be_clickable((By.ID, 'wt-cli-settings-btn'))\n",
    "        )\n",
    "        cookie_button.click()\n",
    "        time.sleep(2)  # Wait for the consent dialog to close\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to close cookie consent: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07aeb55",
   "metadata": {},
   "source": [
    "#### Define the helper function for 'robots.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831eb697",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "88c3805f",
   "metadata": {},
   "source": [
    "## Ledger Insights Scraper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4619929a",
   "metadata": {},
   "source": [
    "#### Setup and initializtion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85cba813",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize WebDriver for Ledger Insights\n",
    "driver = webdriver.Chrome(service=service, options=options)\n",
    "driver.get(ledger_insights_url)\n",
    "\n",
    "# Define the CSV file headers\n",
    "headers = ['headline', 'link', 'date']\n",
    "\n",
    "# Read existing headlines to avoid duplicates\n",
    "existing_headlines = set()\n",
    "if csv_file_exists_and_has_headers(csv_file_path, headers):\n",
    "    with open(csv_file_path, 'r', encoding='utf-8') as read_file:\n",
    "        csv_reader = csv.reader(read_file)\n",
    "        next(csv_reader)  # Skip header row\n",
    "        for row in csv_reader:\n",
    "            if row:\n",
    "                existing_headlines.add(row[0])\n",
    "                \n",
    "# Close cookie consent if it appears\n",
    "close_cookie_consent()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255da348",
   "metadata": {},
   "source": [
    "#### Loading, parsing and scraping articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac38ecf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load articles by clicking the 'Load More' button multiple times\n",
    "for _ in range(num_clicks_li):\n",
    "    try:\n",
    "        load_more_button = WebDriverWait(driver, 10).until(\n",
    "            EC.element_to_be_clickable((By.XPATH, '//a[contains(text(), \"Load more\")]'))\n",
    "        )\n",
    "        load_more_button.click()\n",
    "        time.sleep(3)  # Wait for the content to load\n",
    "    except Exception as e:\n",
    "        print(f\"Exception occurred: {e}\")\n",
    "        break\n",
    "\n",
    "# Parse the loaded page content with BeautifulSoup\n",
    "soup = BeautifulSoup(driver.page_source, 'lxml')\n",
    "\n",
    "# Use a set to store seen links to avoid duplication\n",
    "seen_links = set()\n",
    "\n",
    "# Loop through each link that might contain a headline\n",
    "ledger_data = []\n",
    "for link in soup.find_all('a', title=True):\n",
    "    headline = link.get('title').strip()\n",
    "    url = link.get('href')\n",
    "\n",
    "    # Check if the link is already processed or the headline already exists in the CSV file\n",
    "    if url in seen_links or headline in existing_headlines:\n",
    "        continue\n",
    "\n",
    "    # Check if any of the keywords are in the headline\n",
    "    if any(keyword in headline.lower() for keyword in keywords):\n",
    "        # Mark this link as seen\n",
    "        seen_links.add(url)\n",
    "\n",
    "        # Open the article in a new tab to fetch the date\n",
    "        driver.execute_script(\"window.open(arguments[0], '_blank');\", url)\n",
    "        driver.switch_to.window(driver.window_handles[1])\n",
    "        \n",
    "        try:\n",
    "            # Wait for the date element to be present\n",
    "            date_element = WebDriverWait(driver, 10).until(\n",
    "                EC.presence_of_element_located((By.CLASS_NAME, 'updated'))\n",
    "            )\n",
    "            date_text = date_element.text\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching date for article {headline}: {e}\")\n",
    "            date_text = \"Unknown\"\n",
    "        \n",
    "        # Close the new tab and switch back to the main tab\n",
    "        driver.close()\n",
    "        driver.switch_to.window(driver.window_handles[0])\n",
    "        \n",
    "        # Print the scraped data to the console\n",
    "        print(f\"Headline: {headline}\")\n",
    "        print(f\"Link: {url}\")\n",
    "        print(f\"Date: {date_text}\")\n",
    "        \n",
    "        # Add the data to ledger_data\n",
    "        ledger_data.append([headline, url, date_text])\n",
    "\n",
    "# Close the WebDriver\n",
    "driver.quit()\n",
    "\n",
    "# Append Ledger Insights data to CSV\n",
    "append_to_csv(csv_file_path, ledger_data, headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01571910",
   "metadata": {},
   "source": [
    "## Blockworks Scraper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f185571",
   "metadata": {},
   "source": [
    "#### Setup and initializtion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e575dc2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize WebDriver for Blockworks\n",
    "driver = webdriver.Chrome(service=service, options=options)\n",
    "driver.get(blockworks_url)\n",
    "\n",
    "# Read existing headlines to avoid duplicates\n",
    "existing_headlines = set()\n",
    "if csv_file_exists_and_has_headers(csv_file_path, headers):\n",
    "    with open(csv_file_path, 'r', encoding='utf-8') as read_file:\n",
    "        csv_reader = csv.reader(read_file)\n",
    "        next(csv_reader)  # Skip header row\n",
    "        for row in csv_reader:\n",
    "            if row:\n",
    "                existing_headlines.add(row[0])\n",
    "                \n",
    "# Close cookie consent if it appears\n",
    "close_cookie_consent()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6585e069",
   "metadata": {},
   "source": [
    "#### Loading, parsing and scraping articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab370157",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the search bar and input 'tokeniz'\n",
    "try:\n",
    "    search_bar = WebDriverWait(driver, 20).until(\n",
    "        EC.presence_of_element_located((By.ID, 'blockworks-search'))  # Use correct ID for the search bar\n",
    "    )\n",
    "    search_bar.send_keys(searchword)\n",
    "    search_bar.send_keys(Keys.RETURN)\n",
    "    print(\"Search query submitted.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error locating search bar: {e}\")\n",
    "    driver.quit()\n",
    "    exit()\n",
    "\n",
    "# Load More button click settings\n",
    "for _ in range(num_clicks_bw):\n",
    "    try:\n",
    "        load_more_button = WebDriverWait(driver, 20).until(\n",
    "            EC.element_to_be_clickable((By.XPATH, '//button[text()=\"Load More\"]'))\n",
    "        )\n",
    "        driver.execute_script(\"arguments[0].scrollIntoView(true);\", load_more_button)  # Scroll into view if needed\n",
    "        load_more_button.click()\n",
    "        time.sleep(3)  # Wait for the content to load\n",
    "        print(f\"'Load More' button clicked {_ + 1} times.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Exception occurred while clicking 'Load More': {e}\")\n",
    "        break\n",
    "\n",
    "# Parse the loaded page content with BeautifulSoup\n",
    "soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "# Locate all article links on the search results page\n",
    "article_links = [a['href'] for a in soup.find_all('a', class_='font-headline flex-grow text-base font-semibold leading-snug hover:text-primary')]\n",
    "\n",
    "# Use a set to store seen links to avoid duplication\n",
    "seen_links = set()\n",
    "\n",
    "# Loop through each article link\n",
    "blockworks_data = []\n",
    "for relative_url in article_links:\n",
    "    url = 'https://blockworks.co' + relative_url\n",
    "\n",
    "    # Open the article\n",
    "    driver.execute_script(\"window.open(arguments[0], '_blank');\", url)\n",
    "    driver.switch_to.window(driver.window_handles[1])\n",
    "    \n",
    "    try:\n",
    "        # Extract the headline\n",
    "        headline_tag = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.CLASS_NAME, 'font-headline'))\n",
    "        )\n",
    "        headline = headline_tag.text.strip()\n",
    "\n",
    "        # Extract the date\n",
    "        date_tag = driver.find_element(By.TAG_NAME, 'time')\n",
    "        date_text = date_tag.text.strip()\n",
    "        \n",
    "        # Print the scraped data to the console\n",
    "        print(f\"Headline: {headline}\")\n",
    "        print(f\"Link: {url}\")\n",
    "        print(f\"Date: {date_text}\")\n",
    "\n",
    "        # Add the data to blockworks_data\n",
    "        if headline not in existing_headlines:\n",
    "            blockworks_data.append([headline, url, date_text])\n",
    "            existing_headlines.add(headline)\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching details for article: {e}\")\n",
    "    \n",
    "    # Close the new tab and switch back to the main tab\n",
    "    driver.close()\n",
    "    driver.switch_to.window(driver.window_handles[0])\n",
    "\n",
    "# Close the WebDriver\n",
    "driver.quit()\n",
    "\n",
    "# Append Blockworks data to CSV\n",
    "append_to_csv(csv_file_path, blockworks_data, headers)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
