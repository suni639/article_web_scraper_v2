{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9f4ea9b",
   "metadata": {},
   "source": [
    "# Article Web Scraper\n",
    "\n",
    "## Introduction\n",
    "This notebook scrapes the latest articles from Ledger Insights and Blockworks websites and appends the data to a single CSV file named `scraped_articles.csv`. The notebook ensures that the CSV file is not overwritten but appended with new data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94590848",
   "metadata": {},
   "source": [
    "## Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "866dbe9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# automating browser commands\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "# web scraping tool\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# general libraries\n",
    "import csv\n",
    "import time\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576b2b77",
   "metadata": {},
   "source": [
    "## Setup and CSV Handling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5e1592",
   "metadata": {},
   "source": [
    "#### Load configuration from JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44a6f115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: C:\\Users\\sunil\\OneDrive\\Documents\\PythonScripts\\article_web_scraper_v2\n",
      "Does the file exist? True\n",
      "Config loaded successfully: {'webdriver_path': 'C:/Program Files/chromedriver-win64/chromedriver.exe', 'ledger_insights_url': 'https://www.ledgerinsights.com/tokenization/', 'blockworks_url': 'https://blockworks.co/search', 'keywords': ['digital assets', 'digital securities', 'tokenized', 'tokenization', 'bond', 'security', 'asset', 'token'], 'searchword': 'tokeniz', 'num_clicks_li': 20, 'num_clicks_bw': 20, 'csv_file_path': 'scraped_articles.csv'}\n"
     ]
    }
   ],
   "source": [
    "# Set the working directory\n",
    "os.chdir('C:/Users/sunil/OneDrive/Documents/PythonScripts/article_web_scraper_v2')\n",
    "\n",
    "# Print the current working directory to verify\n",
    "print(f\"Current working directory: {os.getcwd()}\")\n",
    "\n",
    "# Path to config.json\n",
    "file_path = 'config.json'\n",
    "\n",
    "# Check if the file exists\n",
    "file_exists = os.path.exists(file_path)\n",
    "print(f\"Does the file exist? {file_exists}\")\n",
    "\n",
    "# If the file exists, load the JSON file\n",
    "if file_exists:\n",
    "    with open(file_path, 'r') as config_file:\n",
    "        config = json.load(config_file)\n",
    "        print(\"Config loaded successfully:\", config)\n",
    "else:\n",
    "    print(f\"File '{file_path}' not found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548a30d5",
   "metadata": {},
   "source": [
    "#### Extract configuration parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a32e87c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "webdriver_path = config['webdriver_path']\n",
    "ledger_insights_url = config['ledger_insights_url']\n",
    "blockworks_url = config['blockworks_url']\n",
    "keywords = config['keywords']\n",
    "num_clicks_li = config['num_clicks_li']\n",
    "num_clicks_bw = config['num_clicks_bw']\n",
    "searchword = config['searchword']\n",
    "csv_file_path = config['csv_file_path']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a773ead0",
   "metadata": {},
   "source": [
    "#### CSV checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91e774e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check if the CSV file exists and contains headers\n",
    "def csv_file_exists_and_has_headers(file_path, headers):\n",
    "    if not os.path.isfile(file_path):\n",
    "        return False\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        first_line = file.readline().strip()\n",
    "        if first_line != ','.join(headers):\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "# Function to append data to CSV\n",
    "def append_to_csv(file_path, data, headers):\n",
    "    file_has_headers = csv_file_exists_and_has_headers(file_path, headers)\n",
    "    with open(file_path, mode='a', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        if not file_has_headers:\n",
    "            writer.writerow(headers)\n",
    "        writer.writerows(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8dfc8b1",
   "metadata": {},
   "source": [
    "#### Selenium setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "edb8b194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Selenium WebDriver\n",
    "service = Service(webdriver_path)\n",
    "options = Options()\n",
    "# options.add_argument('--headless')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afcc9a6c",
   "metadata": {},
   "source": [
    "#### Interacting with cookie consent button"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3738df25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to close cookie consent button\n",
    "def close_cookie_consent():\n",
    "    try:\n",
    "        cookie_button = WebDriverWait(driver, 10).until(\n",
    "            EC.element_to_be_clickable((By.ID, 'wt-cli-settings-btn'))\n",
    "        )\n",
    "        cookie_button.click()\n",
    "        time.sleep(2)  # Wait for the consent dialog to close\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to close cookie consent: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd98d176",
   "metadata": {},
   "source": [
    "#### Define the helper function for 'robots.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5d708259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "robots.txt content for https://www.ledgerinsights.com/robots.txt:\n",
      "\n",
      "User-Agent: *\n",
      "Disallow: /wp-admin/\n",
      "Allow: /wp-admin/admin-ajax.php\n",
      "\n",
      "User-agent: AhrefsBot\n",
      "Crawl-Delay: 60\n",
      "\n",
      "Failed to fetch robots.txt from https://blockworks.co/robots.txt\n",
      "Failed to initialize RobotFileParser for Blockworks; proceeding with scraping based on assumed allowance.\n"
     ]
    }
   ],
   "source": [
    "# Function to fetch and print robots.txt content\n",
    "def fetch_and_print_robots_txt(url):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            print(f\"robots.txt content for {url}:\\n{response.text}\")\n",
    "            rp = RobotFileParser()\n",
    "            rp.parse(response.text.split('\\n'))\n",
    "            return rp\n",
    "        else:\n",
    "            print(f\"Failed to fetch robots.txt from {url}\")\n",
    "            return None\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Exception occurred while fetching robots.txt from {url}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Fetch and print robots.txt for Ledger Insights\n",
    "ledger_insights_robots_url = \"https://www.ledgerinsights.com/robots.txt\"\n",
    "ledger_rp = fetch_and_print_robots_txt(ledger_insights_robots_url)\n",
    "    \n",
    "# Fetch and print robots.txt for Blockworks\n",
    "blockworks_robots_url = \"https://blockworks.co/robots.txt\"\n",
    "blockworks_rp = fetch_and_print_robots_txt(blockworks_robots_url)\n",
    "\n",
    "# Check specific URL access for Blockworks\n",
    "blockworks_test_url = blockworks_url  # Use the base URL or a specific URL you want to test\n",
    "if blockworks_rp:\n",
    "    print(f\"Testing URL access for {blockworks_test_url}\")\n",
    "    if blockworks_rp.can_fetch(\"*\", blockworks_test_url):\n",
    "        print(f\"Allowed to scrape: {blockworks_test_url}\")\n",
    "    else:\n",
    "        print(f\"Not allowed to scrape: {blockworks_test_url}\")\n",
    "else:\n",
    "    print(\"Failed to initialize RobotFileParser for Blockworks; proceeding with scraping based on assumed allowance.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89b941c",
   "metadata": {},
   "source": [
    "#### Check to ensure we are allowed to scrape from sites\n",
    "This is done by assessing and complying with the associated 'robots.txt' files embedded within a site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9e5c4fc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Allowed to scrape: https://www.ledgerinsights.com/tokenization/\n",
      "Allowed to scrape: https://blockworks.co/search\n"
     ]
    }
   ],
   "source": [
    "# Function to scrape Ledger Insights articles\n",
    "def scrape_ledger_insights():\n",
    "    urls_to_scrape = [\n",
    "        ledger_insights_url,\n",
    "        # Add more URLs as needed\n",
    "    ]\n",
    "\n",
    "    for url in urls_to_scrape:\n",
    "        if ledger_rp.can_fetch(\"*\", url):\n",
    "            print(f\"Allowed to scrape: {url}\")\n",
    "            response = requests.get(url)\n",
    "            # Continue with your scraping logic (i.e. parsing the page with BeautifulSoup)\n",
    "        else:\n",
    "            print(f\"Not allowed to scrape: {url}\")\n",
    "\n",
    "# Function to scrape Blockworks articles\n",
    "def scrape_blockworks():\n",
    "    urls_to_scrape = [\n",
    "        blockworks_url,\n",
    "        # Add more URLs as needed\n",
    "    ]\n",
    "\n",
    "    for url in urls_to_scrape:\n",
    "        # Proceed if robots.txt is not fetched, assuming scraping is allowed\n",
    "        if blockworks_rp is None or blockworks_rp.can_fetch(\"*\", url):\n",
    "            print(f\"Allowed to scrape: {url}\")\n",
    "            response = requests.get(url)\n",
    "            # Continue with scraping logic (i.e. parsing the page with BeautifulSoup)\n",
    "        else:\n",
    "            print(f\"Not allowed to scrape: {url}\")\n",
    "\n",
    "# Run the scraping functions\n",
    "scrape_ledger_insights()\n",
    "scrape_blockworks()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c3805f",
   "metadata": {},
   "source": [
    "## Ledger Insights Scraper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4619929a",
   "metadata": {},
   "source": [
    "#### Setup and initializtion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "85cba813",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize WebDriver for Ledger Insights\n",
    "driver = webdriver.Chrome(service=service, options=options)\n",
    "driver.get(ledger_insights_url)\n",
    "\n",
    "# Define the CSV file headers\n",
    "headers = ['headline', 'link', 'date']\n",
    "\n",
    "# Read existing headlines to avoid duplicates\n",
    "existing_headlines = set()\n",
    "if csv_file_exists_and_has_headers(csv_file_path, headers):\n",
    "    with open(csv_file_path, 'r', encoding='utf-8') as read_file:\n",
    "        csv_reader = csv.reader(read_file)\n",
    "        next(csv_reader)  # Skip header row\n",
    "        for row in csv_reader:\n",
    "            if row:\n",
    "                existing_headlines.add(row[0])\n",
    "                \n",
    "# Close cookie consent if it appears\n",
    "close_cookie_consent()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255da348",
   "metadata": {},
   "source": [
    "#### Loading, parsing and scraping articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ac38ecf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Headline: Glasstower plans to use tokenized money market funds for cross border payments\n",
      "Link: https://www.ledgerinsights.com/glasstower-plans-to-use-tokenized-money-market-funds-for-cross-border-payments/\n",
      "Date: May 16, 2024\n"
     ]
    }
   ],
   "source": [
    "# Load articles by clicking the 'Load More' button multiple times\n",
    "for _ in range(num_clicks_li):\n",
    "    try:\n",
    "        load_more_button = WebDriverWait(driver, 10).until(\n",
    "            EC.element_to_be_clickable((By.XPATH, '//a[contains(text(), \"Load more\")]'))\n",
    "        )\n",
    "        load_more_button.click()\n",
    "        time.sleep(3)  # Wait for the content to load\n",
    "    except Exception as e:\n",
    "        print(f\"Exception occurred: {e}\")\n",
    "        break\n",
    "\n",
    "# Parse the loaded page content with BeautifulSoup\n",
    "soup = BeautifulSoup(driver.page_source, 'lxml')\n",
    "\n",
    "# Use a set to store seen links to avoid duplication\n",
    "seen_links = set()\n",
    "\n",
    "# Loop through each link that might contain a headline\n",
    "ledger_data = []\n",
    "for link in soup.find_all('a', title=True):\n",
    "    headline = link.get('title').strip()\n",
    "    url = link.get('href')\n",
    "\n",
    "    # Check if the link is already processed or the headline already exists in the CSV file\n",
    "    if url in seen_links or headline in existing_headlines:\n",
    "        continue\n",
    "\n",
    "    # Check if any of the keywords are in the headline\n",
    "    if any(keyword in headline.lower() for keyword in keywords):\n",
    "        # Mark this link as seen\n",
    "        seen_links.add(url)\n",
    "\n",
    "        # Open the article in a new tab to fetch the date\n",
    "        driver.execute_script(\"window.open(arguments[0], '_blank');\", url)\n",
    "        driver.switch_to.window(driver.window_handles[1])\n",
    "        \n",
    "        try:\n",
    "            # Wait for the date element to be present\n",
    "            date_element = WebDriverWait(driver, 10).until(\n",
    "                EC.presence_of_element_located((By.CLASS_NAME, 'updated'))\n",
    "            )\n",
    "            date_text = date_element.text\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching date for article {headline}: {e}\")\n",
    "            date_text = \"Unknown\"\n",
    "        \n",
    "        # Close the new tab and switch back to the main tab\n",
    "        driver.close()\n",
    "        driver.switch_to.window(driver.window_handles[0])\n",
    "        \n",
    "        # Print the scraped data to the console\n",
    "        print(f\"Headline: {headline}\")\n",
    "        print(f\"Link: {url}\")\n",
    "        print(f\"Date: {date_text}\")\n",
    "        \n",
    "        # Add the data to ledger_data\n",
    "        ledger_data.append([headline, url, date_text])\n",
    "\n",
    "# Close the WebDriver\n",
    "driver.quit()\n",
    "\n",
    "# Append Ledger Insights data to CSV\n",
    "append_to_csv(csv_file_path, ledger_data, headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01571910",
   "metadata": {},
   "source": [
    "## Blockworks Scraper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f185571",
   "metadata": {},
   "source": [
    "#### Setup and initializtion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e575dc2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to close cookie consent: Message: \n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00007FF7298B1522+60802]\n",
      "\t(No symbol) [0x00007FF72982AC22]\n",
      "\t(No symbol) [0x00007FF7296E7CE4]\n",
      "\t(No symbol) [0x00007FF729736D4D]\n",
      "\t(No symbol) [0x00007FF729736E1C]\n",
      "\t(No symbol) [0x00007FF72977CE37]\n",
      "\t(No symbol) [0x00007FF72975ABBF]\n",
      "\t(No symbol) [0x00007FF72977A224]\n",
      "\t(No symbol) [0x00007FF72975A923]\n",
      "\t(No symbol) [0x00007FF729728FEC]\n",
      "\t(No symbol) [0x00007FF729729C21]\n",
      "\tGetHandleVerifier [0x00007FF729BB41BD+3217949]\n",
      "\tGetHandleVerifier [0x00007FF729BF6157+3488183]\n",
      "\tGetHandleVerifier [0x00007FF729BEF0DF+3459391]\n",
      "\tGetHandleVerifier [0x00007FF72996B8E6+823622]\n",
      "\t(No symbol) [0x00007FF729835FBF]\n",
      "\t(No symbol) [0x00007FF729830EE4]\n",
      "\t(No symbol) [0x00007FF729831072]\n",
      "\t(No symbol) [0x00007FF7298218C4]\n",
      "\tBaseThreadInitThunk [0x00007FFC9F27257D+29]\n",
      "\tRtlUserThreadStart [0x00007FFCA0F0AA48+40]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize WebDriver for Blockworks\n",
    "driver = webdriver.Chrome(service=service, options=options)\n",
    "driver.get(blockworks_url)\n",
    "\n",
    "# Read existing headlines to avoid duplicates\n",
    "existing_headlines = set()\n",
    "if csv_file_exists_and_has_headers(csv_file_path, headers):\n",
    "    with open(csv_file_path, 'r', encoding='utf-8') as read_file:\n",
    "        csv_reader = csv.reader(read_file)\n",
    "        next(csv_reader)  # Skip header row\n",
    "        for row in csv_reader:\n",
    "            if row:\n",
    "                existing_headlines.add(row[0])\n",
    "                \n",
    "# Close cookie consent if it appears\n",
    "close_cookie_consent()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6585e069",
   "metadata": {},
   "source": [
    "#### Loading, parsing and scraping articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ab370157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search query submitted.\n",
      "'Load More' button clicked 1 times.\n",
      "'Load More' button clicked 2 times.\n",
      "Exception occurred while clicking 'Load More': Message: \n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00007FF7298B1522+60802]\n",
      "\t(No symbol) [0x00007FF72982AC22]\n",
      "\t(No symbol) [0x00007FF7296E7CE4]\n",
      "\t(No symbol) [0x00007FF729736D4D]\n",
      "\t(No symbol) [0x00007FF729736E1C]\n",
      "\t(No symbol) [0x00007FF72977CE37]\n",
      "\t(No symbol) [0x00007FF72975ABBF]\n",
      "\t(No symbol) [0x00007FF72977A224]\n",
      "\t(No symbol) [0x00007FF72975A923]\n",
      "\t(No symbol) [0x00007FF729728FEC]\n",
      "\t(No symbol) [0x00007FF729729C21]\n",
      "\tGetHandleVerifier [0x00007FF729BB41BD+3217949]\n",
      "\tGetHandleVerifier [0x00007FF729BF6157+3488183]\n",
      "\tGetHandleVerifier [0x00007FF729BEF0DF+3459391]\n",
      "\tGetHandleVerifier [0x00007FF72996B8E6+823622]\n",
      "\t(No symbol) [0x00007FF729835FBF]\n",
      "\t(No symbol) [0x00007FF729830EE4]\n",
      "\t(No symbol) [0x00007FF729831072]\n",
      "\t(No symbol) [0x00007FF7298218C4]\n",
      "\tBaseThreadInitThunk [0x00007FFC9F27257D+29]\n",
      "\tRtlUserThreadStart [0x00007FFCA0F0AA48+40]\n",
      "\n",
      "Headline: Binance executive denied bail in Nigeria\n",
      "Link: https://blockworks.co/news/binance-executive-denied-bail-in-nigeria\n",
      "Date: MAY 17, 2024 11:26 AM\n",
      "Headline: From BTC to HPC: Miners signal evolving focus after the halving\n",
      "Link: https://blockworks.co/news/btc-miners-evolving-revenue-post-halving\n",
      "Date: MAY 17, 2024 11:02 AM\n",
      "Headline: Oklahoma passes bill protecting ‘fundamental bitcoin rights’\n",
      "Link: https://blockworks.co/news/oklahoma-bill-protects-fundamental-bitcoin-rights\n",
      "Date: MAY 17, 2024 09:58 AM\n",
      "Headline: Solana restaking protocol Solayer soft-launches deposits\n",
      "Link: https://blockworks.co/news/solana-restaking-protocol-solayer\n",
      "Date: MAY 16, 2024 04:46 PM\n",
      "Headline: Senate passes resolution to overturn SAB 121\n",
      "Link: https://blockworks.co/news/senate-passes-resolution-to-overturn-sab121\n",
      "Date: MAY 16, 2024 03:17 PM\n",
      "Headline: Pump.fun pauses trading after apparent flash loan attack\n",
      "Link: https://blockworks.co/news/pump-fun-flash-loan-attack\n",
      "Date: MAY 16, 2024 02:40 PM\n",
      "Headline: How are advisers using bitcoin ETFs in client portfolios? It depends.\n",
      "Link: https://blockworks.co/news/advisers-bitcoin-etfs-client-portfolios\n",
      "Date: MAY 16, 2024 02:01 PM\n",
      "Headline: Empire Newsletter: Taking stock of who’s buying which bitcoin ETF\n",
      "Link: https://blockworks.co/news/empire-newsletter-bitcoin-etf-shareholders\n",
      "Date: MAY 16, 2024 09:44 AM\n",
      "Headline: It’s time to overturn SAB 121\n",
      "Link: https://blockworks.co/news/senate-gensler-sec-overturn-sab-121\n",
      "Date: MAY 15, 2024 05:03 PM\n",
      "Headline: Senate predicted to overturn SAB 121 in vote Thursday, Hill sources say\n",
      "Link: https://blockworks.co/news/senate-vote-sab-121\n",
      "Date: MAY 15, 2024 02:55 PM\n",
      "Headline: Lightspeed Newsletter: Helium eyes the big guys\n",
      "Link: https://blockworks.co/news/lightspeed-newsletter-helium-cell-coverage\n",
      "Date: MAY 15, 2024 01:52 PM\n",
      "Headline: DOJ charges 2 brothers tied to $25M attack on MEV bots last year\n",
      "Link: https://blockworks.co/news/doj-charges-brothers-mev-bot-attack\n",
      "Date: MAY 15, 2024 12:46 PM\n",
      "Headline: JPMorgan tests tokenized portfolios with Avalanche blockchain tech\n",
      "Link: https://blockworks.co/news/jpmorgan-tokenized-blockchain-portfolio-avalanche\n",
      "Date: NOVEMBER 16, 2023 05:34 AM\n",
      "Headline: Tokenization top of mind for Hong Kong’s securities regulator\n",
      "Link: https://blockworks.co/news/hong-kong-regulator-tokenization\n",
      "Date: NOVEMBER 8, 2023 04:05 PM\n",
      "Headline: HSBC to round out tokenization offering via custody play\n",
      "Link: https://blockworks.co/news/hsbc-tokenization-custody\n",
      "Date: NOVEMBER 8, 2023 11:03 AM\n",
      "Headline: Could tokenizing unique real-world assets make DeFi exciting again?\n",
      "Link: https://blockworks.co/news/defi-tokenization-real-world-assets-empire\n",
      "Date: OCTOBER 30, 2023 09:03 AM\n",
      "Headline: A new EIP aims to revamp the tokenized vaults standard for RWAs\n",
      "Link: https://blockworks.co/news/eip-rwa-tokenized-vault-standards\n",
      "Date: OCTOBER 20, 2023 02:48 PM\n",
      "Headline: Australian markets could see billions in savings via tokenization: RBA\n",
      "Link: https://blockworks.co/news/australia-savings-tokenization-cbdc\n",
      "Date: OCTOBER 16, 2023 01:16 PM\n",
      "Headline: Tokenized short-term US Treasury ETF coming to Base\n",
      "Link: https://blockworks.co/news/base-tokenized-securities-coinbase-treasury-bond-etf\n",
      "Date: OCTOBER 6, 2023 10:01 AM\n",
      "Headline: UBS trials tokenized money market fund on Ethereum\n",
      "Link: https://blockworks.co/news/ubs-switzerland-tokenized-fund-ethereum\n",
      "Date: OCTOBER 2, 2023 09:17 AM\n",
      "Headline: Fireblocks acquires tokenization firm BlockFold\n",
      "Link: https://blockworks.co/news/fireblocks-blockfold-tokenization-acquisition\n",
      "Date: SEPTEMBER 29, 2023 10:41 AM\n",
      "Headline: Gensler: Bitcoin is not a security, but tokenized Pokemon cards may be\n",
      "Link: https://blockworks.co/news/gensler-testimony-pokemon-bitcoin\n",
      "Date: SEPTEMBER 27, 2023 03:25 PM\n",
      "Headline: Financial giant Deutsche Bank eyes crypto custody, tokenization\n",
      "Link: https://blockworks.co/news/deutsche-bank-crypto-custody-tokenization\n",
      "Date: SEPTEMBER 14, 2023 08:00 AM\n",
      "Headline: Korean finance giant links up with Polygon Labs on tokenized securities\n",
      "Link: https://blockworks.co/news/mirae-partners-with-polygon-labs\n",
      "Date: SEPTEMBER 6, 2023 09:00 PM\n",
      "Headline: Tokenized vaults see steady deployments remain after ERC-4626 adoption\n",
      "Link: https://blockworks.co/news/tokenized-vault-ethereum-erc-4626\n",
      "Date: SEPTEMBER 1, 2023 12:16 PM\n",
      "Headline: Why tokenized smart batteries are a ‘net new asset class’\n",
      "Link: https://blockworks.co/news/entheos-renewable-energy-smart-batteries\n",
      "Date: AUGUST 31, 2023 05:36 PM\n",
      "Headline: TradFi, DeFi convergence continues through tokenizing real-world assets\n",
      "Link: https://blockworks.co/news/real-world-assets-tradfi-defi-tokenization\n",
      "Date: AUGUST 31, 2023 12:09 PM\n",
      "Headline: Securitize deal to access RIA market latest step of tokenization growth journey\n",
      "Link: https://blockworks.co/news/securitize-ria-market-tokenization-growth\n",
      "Date: AUGUST 18, 2023 08:36 AM\n",
      "Headline: We’re thinking about tokenization all wrong\n",
      "Link: https://blockworks.co/news/tokenization-standards-finance-crypto\n",
      "Date: AUGUST 17, 2023 12:46 PM\n",
      "Headline: Republic’s new multi-chain wallet is tailored for tokenized assets\n",
      "Link: https://blockworks.co/news/republic-digital-wallet\n",
      "Date: AUGUST 17, 2023 09:30 AM\n",
      "Headline: ‘Non-fungible plants’ are right up there with tokenized farts in jars\n",
      "Link: https://blockworks.co/news/nft-plants-decentralized-blockchain\n",
      "Date: JULY 21, 2023 01:51 PM\n",
      "Headline: Combine CBDCs, tokenized deposits on a unified ledger, BIS says\n",
      "Link: https://blockworks.co/news/cbdcs-tokenized-deposits-unified-ledger\n",
      "Date: JUNE 21, 2023 11:31 AM\n",
      "Headline: Tokenized US Treasury bills are entering emerging markets\n",
      "Link: https://blockworks.co/news/tokenized-us-treasury-bills\n",
      "Date: JUNE 13, 2023 03:00 AM\n",
      "Headline: Bank of China investment arm issues tokenized notes on Ethereum\n",
      "Link: https://blockworks.co/news/boc-investment-arm-tokenized-notes\n",
      "Date: JUNE 12, 2023 12:25 PM\n",
      "Headline: Tokenized Assets, Distributed Ledgers Could Save Finance Billions: GFMA\n",
      "Link: https://blockworks.co/news/tokenized-distributed-ledgers-gfma\n",
      "Date: MAY 17, 2023 08:10 AM\n",
      "Headline: Nigeria SEC Okays Tokenized Assets, but Crypto Will Have to Wait\n",
      "Link: https://blockworks.co/news/nigeria-tokenized-securities-crypto\n",
      "Date: MAY 4, 2023 08:14 AM\n"
     ]
    }
   ],
   "source": [
    "# Find the search bar and input 'tokeniz'\n",
    "try:\n",
    "    search_bar = WebDriverWait(driver, 20).until(\n",
    "        EC.presence_of_element_located((By.ID, 'blockworks-search'))  # Use correct ID for the search bar\n",
    "    )\n",
    "    search_bar.send_keys(searchword)\n",
    "    search_bar.send_keys(Keys.RETURN)\n",
    "    print(\"Search query submitted.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error locating search bar: {e}\")\n",
    "    driver.quit()\n",
    "    exit()\n",
    "\n",
    "# Load More button click settings\n",
    "for _ in range(num_clicks_bw):\n",
    "    try:\n",
    "        load_more_button = WebDriverWait(driver, 20).until(\n",
    "            EC.element_to_be_clickable((By.XPATH, '//button[text()=\"Load More\"]'))\n",
    "        )\n",
    "        driver.execute_script(\"arguments[0].scrollIntoView(true);\", load_more_button)  # Scroll into view if needed\n",
    "        load_more_button.click()\n",
    "        time.sleep(3)  # Wait for the content to load\n",
    "        print(f\"'Load More' button clicked {_ + 1} times.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Exception occurred while clicking 'Load More': {e}\")\n",
    "        break\n",
    "\n",
    "# Parse the loaded page content with BeautifulSoup\n",
    "soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "# Locate all article links on the search results page\n",
    "article_links = [a['href'] for a in soup.find_all('a', class_='font-headline flex-grow text-base font-semibold leading-snug hover:text-primary')]\n",
    "\n",
    "# Use a set to store seen links to avoid duplication\n",
    "seen_links = set()\n",
    "\n",
    "# Loop through each article link\n",
    "blockworks_data = []\n",
    "for relative_url in article_links:\n",
    "    url = 'https://blockworks.co' + relative_url\n",
    "\n",
    "    # Open the article\n",
    "    driver.execute_script(\"window.open(arguments[0], '_blank');\", url)\n",
    "    driver.switch_to.window(driver.window_handles[1])\n",
    "    \n",
    "    try:\n",
    "        # Extract the headline\n",
    "        headline_tag = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.CLASS_NAME, 'font-headline'))\n",
    "        )\n",
    "        headline = headline_tag.text.strip()\n",
    "\n",
    "        # Extract the date\n",
    "        date_tag = driver.find_element(By.TAG_NAME, 'time')\n",
    "        date_text = date_tag.text.strip()\n",
    "        \n",
    "        # Print the scraped data to the console\n",
    "        print(f\"Headline: {headline}\")\n",
    "        print(f\"Link: {url}\")\n",
    "        print(f\"Date: {date_text}\")\n",
    "\n",
    "        # Add the data to blockworks_data\n",
    "        if headline not in existing_headlines:\n",
    "            blockworks_data.append([headline, url, date_text])\n",
    "            existing_headlines.add(headline)\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching details for article: {e}\")\n",
    "    \n",
    "    # Close the new tab and switch back to the main tab\n",
    "    driver.close()\n",
    "    driver.switch_to.window(driver.window_handles[0])\n",
    "\n",
    "# Close the WebDriver\n",
    "driver.quit()\n",
    "\n",
    "# Append Blockworks data to CSV\n",
    "append_to_csv(csv_file_path, blockworks_data, headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1aa0299",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
